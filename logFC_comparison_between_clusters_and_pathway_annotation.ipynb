{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
    "import numpy as np\n",
    "import time\n",
    "from bioservices.kegg import KEGG\n",
    "from biomart import BiomartServer\n",
    "from io import StringIO\n",
    "\n",
    "# Define clusters for analysis\n",
    "cluster_pairs = [\n",
    "    ('Silver nitrate', 'Sorbitol', 'Freeze-Thaw', 'Aluminum chloride', 'Potassium chloride', 'Hydrogen peroxide', 'Heat Stress'),\n",
    "    ('Cobalt', 'Nickel', 'Vanillin', 'Propolis'),\n",
    "    ('Ethanol', 'Boron', 'Sodium acetate', 'Phenyl ethanol', 'Chromium(III) chloride', 'Ammonium iron(III) sulfate', 'Manganese(II) chloride'),\n",
    "    ('Methanol', 'Magnesium chloride', 'Acetate'),\n",
    "    ('Copper', 'Sodium chloride'),\n",
    "    ('Rapamycin', 'Caffeine', 'Coniferyl aldehyde')\n",
    "]\n",
    "\n",
    "# Dictionary to store unique and significant genes for each cluster\n",
    "unique_genes = {}\n",
    "significant_genes = {}\n",
    "\n",
    "# Helper function to split a list into chunks of size n\n",
    "def split_list(lst, n):\n",
    "    \"\"\"Split the list into chunks of size n.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# Function to fetch gene information from Biomart\n",
    "def get_gene_info(gene_ids):\n",
    "    \"\"\"Fetch gene details like GO terms and descriptions from Biomart.\"\"\"\n",
    "    # Connect to the Biomart server\n",
    "    server = BiomartServer(\"http://www.ensembl.org/biomart\")\n",
    "    server.verbose = True\n",
    "    \n",
    "    # Select the yeast dataset\n",
    "    dataset = server.datasets['scerevisiae_gene_ensembl']\n",
    "    \n",
    "    # Split gene list into manageable chunks\n",
    "    all_chunks = list(split_list(gene_ids, 50))\n",
    "    dfs = []\n",
    "    \n",
    "    for chunk in all_chunks:\n",
    "        try:\n",
    "            # Query Biomart for gene information\n",
    "            response = dataset.search({\n",
    "                'filters': {\n",
    "                    'ensembl_gene_id': chunk\n",
    "                },\n",
    "                'attributes': [\n",
    "                    'ensembl_gene_id',\n",
    "                    'external_gene_name',\n",
    "                    'description',\n",
    "                    'go_id',  # Gene Ontology ID\n",
    "                    'name_1006',  # GO term name\n",
    "                ]\n",
    "            })\n",
    "            \n",
    "            # Convert response to DataFrame\n",
    "            data = response.text\n",
    "            if data.strip():  # If data exists\n",
    "                df = pd.read_csv(StringIO(data), sep='\\t', header=None, names=['ensembl_gene_id', 'external_gene_name', 'description', 'go_id', 'go_term'])\n",
    "                dfs.append(df)\n",
    "            \n",
    "            # Pause to avoid overloading the server\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for chunk: {chunk} - {e}\")\n",
    "    \n",
    "    # Concatenate all chunks into a final DataFrame\n",
    "    if dfs:\n",
    "        final_df = pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        final_df = pd.DataFrame(columns=['ensembl_gene_id', 'external_gene_name', 'description', 'go_id', 'go_term'])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Function to convert gene IDs to gene names, descriptions, and GO terms\n",
    "def convert_gene_ids(gene_ids):\n",
    "    \"\"\"Convert Ensembl gene IDs to gene names and descriptions using Biomart.\"\"\"\n",
    "    gene_info_df = get_gene_info(gene_ids)\n",
    "    \n",
    "    # Group by ensembl_gene_id and aggregate GO terms\n",
    "    gene_info_df_grouped = gene_info_df.groupby('ensembl_gene_id').agg({\n",
    "        'external_gene_name': 'first',\n",
    "        'description': 'first',\n",
    "        'go_id': lambda x: '; '.join(x.dropna().unique()),\n",
    "        'go_term': lambda x: '; '.join(x.dropna().unique())\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Convert to dictionary format\n",
    "    gene_info_dict = gene_info_df_grouped.set_index('ensembl_gene_id').to_dict(orient='index')\n",
    "    return gene_info_dict\n",
    "\n",
    "# Function for KEGG pathway analysis\n",
    "def kegg_pathway_analysis(gene_list):\n",
    "    \"\"\"Retrieve KEGG pathways for a list of genes.\"\"\"\n",
    "    kegg = KEGG()\n",
    "    kegg.organism = \"sce\"  # KEGG organism code for Saccharomyces cerevisiae\n",
    "    \n",
    "    pathway_dict = {}\n",
    "    for gene in gene_list:\n",
    "        try:\n",
    "            # Retrieve KEGG pathways associated with the gene\n",
    "            pathways = kegg.get_pathway_by_gene(gene, organism=\"sce\")\n",
    "            if pathways:\n",
    "                pathway_dict[gene] = pathways\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing gene {gene}: {e}\")\n",
    "    \n",
    "    return pathway_dict\n",
    "\n",
    "# Loop through each cluster for analysis\n",
    "for cluster in cluster_pairs:\n",
    "    unique_genes[cluster] = {'upregulated': [], 'downregulated': []}\n",
    "    significant_genes[cluster] = {'upregulated': [], 'downregulated': []}\n",
    "    \n",
    "    cluster_samples = list(cluster)  # Samples for the current cluster\n",
    "    other_samples = [col for col in df.columns if col not in cluster_samples]  # Samples not in the cluster\n",
    "\n",
    "    # Loop through each gene in the dataframe\n",
    "    for gene in df.index:\n",
    "        cluster_values = df.loc[gene, cluster_samples]  # Values for cluster samples\n",
    "        other_values = df.loc[gene, other_samples]  # Values for other samples\n",
    "\n",
    "        # Check for unique expression pattern in the cluster\n",
    "        if (cluster_values != 0).all() and (other_values == 0).all():\n",
    "            if (cluster_values > 0).all():\n",
    "                unique_genes[cluster]['upregulated'].append(gene)\n",
    "            elif (cluster_values < 0).all():\n",
    "                unique_genes[cluster]['downregulated'].append(gene)\n",
    "        else:\n",
    "            # Perform normality test\n",
    "            if len(cluster_values) >= 3 and len(other_values) >= 3:\n",
    "                cluster_normal = shapiro(cluster_values)[1] > 0.05\n",
    "                other_normal = shapiro(other_values)[1] > 0.05\n",
    "\n",
    "                # Apply t-test or Mann-Whitney U test based on normality\n",
    "                if cluster_normal and other_normal:\n",
    "                    stat, p_value = ttest_ind(cluster_values, other_values)\n",
    "                else:\n",
    "                    stat, p_value = mannwhitneyu(cluster_values, other_values)\n",
    "\n",
    "                # If p-value is significant, classify as upregulated or downregulated\n",
    "                if p_value < 0.05:\n",
    "                    if cluster_values.mean() > other_values.mean():\n",
    "                        significant_genes[cluster]['upregulated'].append(gene)\n",
    "                    else:\n",
    "                        significant_genes[cluster]['downregulated'].append(gene)\n",
    "\n",
    "# Convert gene IDs to gene names and descriptions\n",
    "all_genes = set()\n",
    "for cluster in cluster_pairs:\n",
    "    all_genes.update(unique_genes[cluster]['upregulated'])\n",
    "    all_genes.update(unique_genes[cluster]['downregulated'])\n",
    "    all_genes.update(significant_genes[cluster]['upregulated'])\n",
    "    all_genes.update(significant_genes[cluster]['downregulated'])\n",
    "\n",
    "gene_info_dict = convert_gene_ids(list(all_genes))\n",
    "\n",
    "# Save results to CSV\n",
    "for cluster in cluster_pairs:\n",
    "    # Create a DataFrame for output\n",
    "    output_df = pd.DataFrame(columns=['Category', 'Gene', 'Gene Name', 'Description', 'GO Terms', 'KEGG Pathways'])\n",
    "    \n",
    "    def add_to_output(category, genes):\n",
    "        \"\"\"Helper function to add genes to the output DataFrame.\"\"\"\n",
    "        for gene in genes:\n",
    "            if gene in gene_info_dict:\n",
    "                go_id = gene_info_dict[gene].get('go_id', '')\n",
    "                go_term = gene_info_dict[gene].get('go_term', '')\n",
    "                go_info = f\"GO: {go_id} - {go_term}\" if go_id or go_term else ''\n",
    "                \n",
    "                try:\n",
    "                    kegg_info = \"; \".join(kegg_pathway_analysis([gene_info_dict[gene]['external_gene_name']])[gene_info_dict[gene]['external_gene_name']])\n",
    "                except KeyError:\n",
    "                    kegg_info = ''\n",
    "\n",
    "                output_df.loc[len(output_df)] = [\n",
    "                    category,\n",
    "                    gene,\n",
    "                    gene_info_dict[gene]['external_gene_name'],\n",
    "                    gene_info_dict[gene]['description'],\n",
    "                    go_info,\n",
    "                    kegg_info\n",
    "                ]\n",
    "            else:\n",
    "                print(f\"Gene {gene} not found in gene_info_dict.\")\n",
    "    \n",
    "    # Add genes from each category to the output DataFrame\n",
    "    add_to_output('Unique Upregulated Genes', unique_genes[cluster]['upregulated'])\n",
    "    add_to_output('Unique Downregulated Genes', unique_genes[cluster]['downregulated'])\n",
    "    add_to_output('Significant Upregulated Genes', significant_genes[cluster]['upregulated'])\n",
    "    add_to_output('Significant Downregulated Genes', significant_genes[cluster]['downregulated'])\n",
    "    \n",
    "    # Save the output to CSV\n",
    "    output_df.to_csv(f'{cluster}_significant_genes.csv', index=False)\n",
    "\n",
    "print(\"Results have been saved to CSV files.\")\n",
    "\n",
    "# CSV file for enrichment analysis\n",
    "csv_file_path = 'path/filename.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Add an enrichment column\n",
    "df['Enrichment'] = \"\"\n",
    "\n",
    "# Function to fetch KEGG pathway information for a gene\n",
    "def get_pathway_info(gene):\n",
    "    \"\"\"Retrieve KEGG pathway descriptions for a given gene.\"\"\"\n",
    "    try:\n",
    "        pathways = kegg.get_pathway_by_gene(gene, organism=\"sce\")\n",
    "        return \"; \".join(pathways.values()) if pathways else \"\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving KEGG data for {gene}: {e}\"\n",
    "\n",
    "# Apply KEGG pathway analysis\n",
    "df['Enrichment'] = df['Gene'].apply(lambda gene: get_pathway_info(gene))\n",
    "\n",
    "# Save the updated DataFrame with KEGG pathways\n",
    "df.to_csv(f'{csv_file_path}_with_kegg.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
